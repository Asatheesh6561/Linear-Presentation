# Linear-Presentation

Code for the Linear Presentation by Aryamann Khanna, Thai-hoa Nguyen, and Anirudh Satheesh for the Attention Mechanism. This is a decoder only transformer that uses the attention mechanism to generate output text that resembles the input text. To use it, copy text into the input.txt file and run attention.py and compare it to bigram.py as a basline.
